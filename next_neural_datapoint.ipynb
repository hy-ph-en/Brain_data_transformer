{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(180000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mnzp0\\AppData\\Local\\Temp\\ipykernel_20928\\4197309928.py:12: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython.display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############### PREDICT NEXT NEURAL TIME SERIES POINT ################ \n",
    "\n",
    "Here we are just trying to get the transformer to learn the dynamics of raw (i.e. PCA denoised) neural time series.\n",
    "\n",
    "#### Step 1: One brain area\n",
    "\n",
    "- input shape [time_points] = [40000]    # this is just a single time series from the visualizion notebook\n",
    "- label: [time_points[1:]]                # here we predict the time series but shifted by 1\n",
    "\n",
    "This is exactly what transformers are developed to do, so we shouldn't have to do too much work to adapt them. We can also smooth or bin the neural data as it's abit noisy. \n",
    "\n",
    "##### Major challenges:\n",
    "\n",
    "1. Figure out how to feed continous time series into the transformer.\n",
    "\n",
    "There are some methods already out there\n",
    "\n",
    "https://huggingface.co/blog/time-series-transformers\n",
    "\n",
    "https://huggingface.co/docs/transformers/model_doc/time_series_transformer\n",
    "\n",
    "\n",
    "#### Step 2: Multiple brain areas\n",
    "\n",
    "- input shape [time_points, n_areas] = [40000, 30]     #  \n",
    "- label: [time_points[1:], 30]                         # \n",
    "\n",
    "##### Major challenges:\n",
    "\n",
    "1. So we would need to extend the above to work with multiple cortical areas...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading The Data\n",
    "root_dir = 'data'\n",
    "mouse_id = 'IA1'\n",
    "session_id = 'Feb_16'\n",
    "\n",
    "# load the raw data from each neural area\n",
    "animal_dir = os.path.join(root_dir, mouse_id, session_id)\n",
    "\n",
    "# find the file using glob that has \"wholestack.npz\" in it\n",
    "fname = glob.glob(os.path.join(animal_dir, '*wholestack.npz'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much are we working with - Reducing initial computational time\n",
    "data_slice = 40000\n",
    "\n",
    "# Load data and verify shape\n",
    "data_stack = np.load(fname, allow_pickle=True)\n",
    "data = data_stack['whole_stack'].T  # Shape: (40000, 16)\n",
    "neural_data = torch.tensor(data[:data_slice], dtype=torch.float32)  # Slice to (1000, 16) - Cut down on the computational complexity\n",
    "\n",
    "\n",
    "# After loading data and slicing to (1000, 16)\n",
    "# Compute mean/std on training data only\n",
    "training_slice = int(data_slice*0.7)\n",
    "train_data = neural_data[:training_slice]  # 70% of 1000 = 700 samples\n",
    "mean = train_data.mean(dim=0)\n",
    "std = train_data.std(dim=0)\n",
    "neural_data_normalized = (neural_data - mean) / (std + 1e-8)\n",
    "\n",
    "window_size = 20  # Adjust with some testing\n",
    "\n",
    "# Regenerate inputs/targets with normalized data\n",
    "inputs, targets = [], []\n",
    "for i in range(window_size, len(neural_data_normalized)):\n",
    "    inputs.append(neural_data_normalized[i-window_size:i])\n",
    "    targets.append(neural_data_normalized[i])\n",
    "\n",
    "\n",
    "# Convert to tensors\n",
    "inputs = torch.stack(inputs)    # Shape: (N, window_size, 16)\n",
    "targets = torch.stack(targets)  # Shape: (N, 16)\n",
    "\n",
    "# Split into train/val/test (70/15/15)\n",
    "train_size = int(0.7 * len(inputs))\n",
    "val_size = int(0.15 * len(inputs))\n",
    "test_size = len(inputs) - train_size - val_size\n",
    "\n",
    "train_dataset = TensorDataset(inputs[:train_size], targets[:train_size])\n",
    "val_dataset = TensorDataset(inputs[train_size:train_size+val_size], targets[train_size:train_size+val_size])\n",
    "test_dataset = TensorDataset(inputs[-test_size:], targets[-test_size:])\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class NeuralTransformer(nn.Module):\n",
    "    def __init__(self, input_dim=16, d_model=64, nhead=4, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Linear(input_dim, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)  # Add LayerNorm\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model, nhead, batch_first=True, dropout=0.1\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.decoder = nn.Linear(d_model, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "        x = self.norm(x)  # Apply LayerNorm\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=1)  # Use mean instead of last timestep\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0306\n",
      "Epoch 2, Loss: 0.0208\n",
      "Epoch 3, Loss: 0.0213\n",
      "Epoch 4, Loss: 0.0196\n",
      "Epoch 5, Loss: 0.0150\n",
      "Epoch 6, Loss: 0.0198\n",
      "Epoch 7, Loss: 0.0184\n",
      "Epoch 8, Loss: 0.0173\n",
      "Epoch 9, Loss: 0.0165\n",
      "Epoch 10, Loss: 0.0174\n",
      "Epoch 11, Loss: 0.0141\n",
      "Epoch 12, Loss: 0.0170\n",
      "Epoch 13, Loss: 0.0161\n",
      "Epoch 14, Loss: 0.0165\n",
      "Epoch 15, Loss: 0.0120\n",
      "Epoch 16, Loss: 0.0123\n",
      "Epoch 17, Loss: 0.0154\n",
      "Epoch 18, Loss: 0.0142\n",
      "Epoch 19, Loss: 0.0165\n",
      "Epoch 20, Loss: 0.0151\n",
      "Epoch 21, Loss: 0.0157\n",
      "Epoch 22, Loss: 0.0134\n",
      "Epoch 23, Loss: 0.0145\n",
      "Epoch 24, Loss: 0.0136\n",
      "Epoch 25, Loss: 0.0144\n",
      "Epoch 26, Loss: 0.0137\n",
      "Epoch 27, Loss: 0.0128\n",
      "Epoch 28, Loss: 0.0148\n",
      "Epoch 29, Loss: 0.0131\n",
      "Epoch 30, Loss: 0.0126\n",
      "Epoch 31, Loss: 0.0137\n",
      "Epoch 32, Loss: 0.0118\n",
      "Epoch 33, Loss: 0.0138\n",
      "Epoch 34, Loss: 0.0135\n",
      "Epoch 35, Loss: 0.0114\n",
      "Epoch 36, Loss: 0.0138\n",
      "Epoch 37, Loss: 0.0129\n",
      "Epoch 38, Loss: 0.0099\n",
      "Epoch 39, Loss: 0.0125\n",
      "Epoch 40, Loss: 0.0158\n",
      "Epoch 41, Loss: 0.0130\n",
      "Epoch 42, Loss: 0.0115\n",
      "Epoch 43, Loss: 0.0091\n",
      "Epoch 44, Loss: 0.0142\n",
      "Epoch 45, Loss: 0.0120\n",
      "Epoch 46, Loss: 0.0110\n",
      "Epoch 47, Loss: 0.0099\n",
      "Epoch 48, Loss: 0.0125\n",
      "Epoch 49, Loss: 0.0154\n",
      "Epoch 50, Loss: 0.0101\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NeuralTransformer().to(device)\n",
    "criterion = nn.HuberLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_inputs, batch_targets in train_loader:\n",
    "        batch_inputs, batch_targets = batch_inputs.to(device), batch_targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        \n",
    "        if torch.isnan(loss):\n",
    "            print(\"NaN detected. Stopping training.\")\n",
    "            break\n",
    "            \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
